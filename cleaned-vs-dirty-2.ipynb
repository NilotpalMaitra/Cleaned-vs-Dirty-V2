{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":15282,"databundleVersionId":565187,"sourceType":"competition"},{"sourceId":8800153,"sourceType":"datasetVersion","datasetId":5291883}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install kaggle\n","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:04:17.022658Z","iopub.execute_input":"2024-06-27T08:04:17.023005Z","iopub.status.idle":"2024-06-27T08:04:31.936003Z","shell.execute_reply.started":"2024-06-27T08:04:17.022979Z","shell.execute_reply":"2024-06-27T08:04:31.934875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport zipfile \nfrom PIL import Image \nimport cv2 \nimport matplotlib.pyplot as plt \nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Conv2D,  BatchNormalization, Input, Flatten, Dropout\nfrom tensorflow.keras.layers import MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.applications import MobileNet, MobileNetV2\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.metrics import Accuracy, Precision, Recall","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:25:51.018295Z","iopub.execute_input":"2024-06-27T08:25:51.019190Z","iopub.status.idle":"2024-06-27T08:26:03.402223Z","shell.execute_reply.started":"2024-06-27T08:25:51.019156Z","shell.execute_reply":"2024-06-27T08:26:03.401458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        # Currently, memory growth needs to be the same across GPUs\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n    except RuntimeError as e:\n        # Memory growth must be set before GPUs have been initialized\n        print(e)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:26:21.112671Z","iopub.execute_input":"2024-06-27T08:26:21.113570Z","iopub.status.idle":"2024-06-27T08:26:21.570705Z","shell.execute_reply.started":"2024-06-27T08:26:21.113537Z","shell.execute_reply":"2024-06-27T08:26:21.569596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plates_file_zip ='/kaggle/input/platesv2/plates.zip'\nplates_img_file = '/kaggle/working/'\nos.makedirs(plates_img_file, exist_ok=True)\nwith zipfile.ZipFile(plates_file_zip, mode='r') as zip_folder:\n    zip_folder.extractall(plates_img_file)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:26:23.672859Z","iopub.execute_input":"2024-06-27T08:26:23.673504Z","iopub.status.idle":"2024-06-27T08:26:24.301348Z","shell.execute_reply.started":"2024-06-27T08:26:23.673470Z","shell.execute_reply":"2024-06-27T08:26:24.300510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_root = '/kaggle/working/plates/'\nprint(os.listdir(data_root))","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:29:06.845925Z","iopub.execute_input":"2024-06-27T08:29:06.846297Z","iopub.status.idle":"2024-06-27T08:29:06.851516Z","shell.execute_reply.started":"2024-06-27T08:29:06.846265Z","shell.execute_reply":"2024-06-27T08:29:06.850514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil \nfrom tqdm import tqdm\n\n\ntrain_dir = 'train'\nval_dir = 'val'\n\nclass_names = ['cleaned', 'dirty']\n\nfor dir_name in [train_dir, val_dir]:\n    for class_name in class_names:\n        os.makedirs(os.path.join(dir_name, class_name), exist_ok=True)\n\nfor class_name in class_names:\n    source_dir = os.path.join(data_root, 'train', class_name)\n    for i, file_name in enumerate(tqdm(os.listdir(source_dir))):\n        if i % 6 != 0:\n            dest_dir = os.path.join(train_dir, class_name) \n        else:\n            dest_dir = os.path.join(val_dir, class_name)\n        shutil.copy(os.path.join(source_dir, file_name), os.path.join(dest_dir, file_name))","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:29:10.695152Z","iopub.execute_input":"2024-06-27T08:29:10.695514Z","iopub.status.idle":"2024-06-27T08:29:10.716676Z","shell.execute_reply.started":"2024-06-27T08:29:10.695485Z","shell.execute_reply":"2024-06-27T08:29:10.715807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls train","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:29:21.669879Z","iopub.execute_input":"2024-06-27T08:29:21.670226Z","iopub.status.idle":"2024-06-27T08:29:22.643060Z","shell.execute_reply.started":"2024-06-27T08:29:21.670198Z","shell.execute_reply":"2024-06-27T08:29:22.642071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Transformations (Data processing and augmentation)\n**","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport torchvision\nimport matplotlib.pyplot as plt\nimport time\nimport copy\n\nfrom torchvision import transforms, models\ntrain_transforms = [\n    transforms.Compose([\n    transforms.CenterCrop(200),\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n    \n    transforms.Compose([\n    transforms.CenterCrop(200),\n    transforms.Resize((224,224)),\n    transforms.ColorJitter(brightness=0.6, contrast=0.6, saturation=0.3, hue=0.3),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n    \n    transforms.Compose([\n    transforms.CenterCrop(200),\n    transforms.Resize((224,224)),\n    transforms.RandomOrder([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n        ]),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n        \n    transforms.Compose([\n    transforms.CenterCrop(200),\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n        \n    transforms.Compose([\n    transforms.RandomRotation(45),\n    transforms.CenterCrop(200),\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n    \n    transforms.Compose([\n    transforms.CenterCrop(200),\n    transforms.Resize((224,224)),\n    transforms.RandomGrayscale(p=1),\n    transforms.RandomOrder([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n        ]),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n        \n    transforms.Compose([\n    transforms.CenterCrop(200),\n    transforms.Resize((224,224)),\n    transforms.ColorJitter(brightness=0.2, contrast=0.4, saturation=0.4, hue=0.4),\n    transforms.RandomVerticalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n]\nval_transforms = transforms.Compose([\n    transforms.CenterCrop(200),\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ntrain_dataset = torch.utils.data.ConcatDataset([torchvision.datasets.ImageFolder(train_dir,train_transform)\n                                                    for train_transform in train_transforms])\n\nval_dataset = torch.utils.data.ConcatDataset([torchvision.datasets.ImageFolder(val_dir,train_transform)\n                                                    for train_transform in train_transforms])\n\nbatch_size = 8\ntrain_dataloader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size)\nval_dataloader = torch.utils.data.DataLoader(\n    val_dataset, batch_size=batch_size, shuffle=False, num_workers=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:29:36.391909Z","iopub.execute_input":"2024-06-27T08:29:36.392867Z","iopub.status.idle":"2024-06-27T08:29:40.580437Z","shell.execute_reply.started":"2024-06-27T08:29:36.392824Z","shell.execute_reply":"2024-06-27T08:29:40.579437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_dataloader), len(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:29:50.901689Z","iopub.execute_input":"2024-06-27T08:29:50.902755Z","iopub.status.idle":"2024-06-27T08:29:50.910398Z","shell.execute_reply.started":"2024-06-27T08:29:50.902719Z","shell.execute_reply":"2024-06-27T08:29:50.909495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_batch, y_batch = next(iter(train_dataloader))\nmean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\nplt.imshow(X_batch[0].permute(1, 2, 0).numpy() * std + mean);","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:30:02.246513Z","iopub.execute_input":"2024-06-27T08:30:02.247134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_input(input_tensor, title=''):\n    image = input_tensor.permute(1, 2, 0).numpy()\n    image = std * image + mean\n    plt.imshow(image.clip(0, 1))\n    plt.title(title)\n    plt.show()\n    plt.pause(0.001)\n\nX_batch, y_batch = next(iter(train_dataloader))\n\nfor x_item, y_item in zip(X_batch, y_batch):\n    show_input(x_item, title=class_names[y_item])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:30:12.230908Z","iopub.execute_input":"2024-06-27T08:30:12.231298Z","iopub.status.idle":"2024-06-27T08:30:15.355040Z","shell.execute_reply.started":"2024-06-27T08:30:12.231254Z","shell.execute_reply":"2024-06-27T08:30:15.353996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, loss, optimizer, scheduler, num_epochs):\n    loss_hist = {'train':[], 'val':[]}\n    accuracy_hist = {'train':[], 'val':[]}\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}:'.format(epoch, num_epochs - 1), flush=True)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                dataloader = train_dataloader\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                dataloader = val_dataloader\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.\n            running_acc = 0.\n\n            # Iterate over data.\n            for inputs, labels in tqdm(dataloader):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                # forward and backward\n                with torch.set_grad_enabled(phase == 'train'):\n                    preds = model(inputs)\n                    loss_value = loss(preds, labels)\n                    preds_class = preds.argmax(dim=1)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss_value.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss_value.item()\n                running_acc += (preds_class == labels.data).float().mean()\n\n            epoch_loss = running_loss / len(dataloader)\n            epoch_acc = running_acc / len(dataloader)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), flush=True)\n            \n            loss_hist[phase].append(epoch_loss)\n            accuracy_hist[phase].append(epoch_acc)\n\n    return model, loss_hist, accuracy_hist","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:30:33.966248Z","iopub.execute_input":"2024-06-27T08:30:33.967163Z","iopub.status.idle":"2024-06-27T08:30:33.978093Z","shell.execute_reply.started":"2024-06-27T08:30:33.967118Z","shell.execute_reply":"2024-06-27T08:30:33.977145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = models.resnet18(pretrained=True)\n\n# Disable grad for all conv layers\nfor param in model.parameters():\n    param.requires_grad = False\n    \nfor param in model.layer4.parameters():\n            param.requires_grad = True\n\nmodel.fc = torch.nn.Sequential(torch.nn.Dropout(0.4),torch.nn.Linear(model.fc.in_features, 64),torch.nn.ReLU(),\n                         torch.nn.BatchNorm1d(num_features=64),torch.nn.Dropout(0.3), torch.nn.Linear(64,2))\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\nloss = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), amsgrad=True, lr=1e-4)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:30:50.726836Z","iopub.execute_input":"2024-06-27T08:30:50.727581Z","iopub.status.idle":"2024-06-27T08:30:51.860991Z","shell.execute_reply.started":"2024-06-27T08:30:50.727549Z","shell.execute_reply":"2024-06-27T08:30:51.860236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, losses, accuracies = train_model(model, loss, optimizer, scheduler, num_epochs=50);","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:35:54.385895Z","iopub.execute_input":"2024-06-27T08:35:54.386979Z","iopub.status.idle":"2024-06-27T08:37:12.328862Z","shell.execute_reply.started":"2024-06-27T08:35:54.386935Z","shell.execute_reply":"2024-06-27T08:37:12.327767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dir = 'test'\nshutil.copytree(os.path.join(data_root, 'test'), os.path.join(test_dir, 'unknown'))","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:37:15.693006Z","iopub.execute_input":"2024-06-27T08:37:15.694137Z","iopub.status.idle":"2024-06-27T08:37:15.817402Z","shell.execute_reply.started":"2024-06-27T08:37:15.694094Z","shell.execute_reply":"2024-06-27T08:37:15.816517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n    def __getitem__(self, index):\n        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n        path = self.imgs[index][0]\n        tuple_with_path = (original_tuple + (path,))\n        return tuple_with_path\n    \ntest_dataset = ImageFolderWithPaths('/kaggle/working/test', val_transforms)\n\ntest_dataloader = torch.utils.data.DataLoader(\n    test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:37:24.780553Z","iopub.execute_input":"2024-06-27T08:37:24.781406Z","iopub.status.idle":"2024-06-27T08:37:24.792123Z","shell.execute_reply.started":"2024-06-27T08:37:24.781376Z","shell.execute_reply":"2024-06-27T08:37:24.791331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:37:33.691389Z","iopub.execute_input":"2024-06-27T08:37:33.691783Z","iopub.status.idle":"2024-06-27T08:37:33.698284Z","shell.execute_reply.started":"2024-06-27T08:37:33.691754Z","shell.execute_reply":"2024-06-27T08:37:33.697296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\n\ntest_predictions = []\ntest_img_paths = []\nfor inputs, labels, paths in tqdm(test_dataloader):\n    inputs = inputs.to(device)\n    labels = labels.to(device)\n    with torch.set_grad_enabled(False):\n        preds = model(inputs)\n    test_predictions.append(\n        torch.nn.functional.softmax(preds, dim=1)[:,1].data.cpu().numpy())\n    test_img_paths.extend(paths)\n    \ntest_predictions = np.concatenate(test_predictions)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:37:43.165508Z","iopub.execute_input":"2024-06-27T08:37:43.165844Z","iopub.status.idle":"2024-06-27T08:37:46.853167Z","shell.execute_reply.started":"2024-06-27T08:37:43.165817Z","shell.execute_reply":"2024-06-27T08:37:46.852254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (14, 7)\nfor experiment_id in losses.keys():\n    plt.plot(losses[experiment_id], label=experiment_id)\nplt.legend(loc='upper left')\nplt.title('Model Loss')\nplt.xlabel('Epoch num', fontsize=15)\nplt.ylabel('Loss function value', fontsize=15)\nplt.grid(linestyle='--', linewidth=0.5, color='.7')","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:38:28.535362Z","iopub.execute_input":"2024-06-27T08:38:28.535741Z","iopub.status.idle":"2024-06-27T08:38:28.900034Z","shell.execute_reply.started":"2024-06-27T08:38:28.535710Z","shell.execute_reply":"2024-06-27T08:38:28.899077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs, labels, paths = next(iter(test_dataloader))\n\nfor img, pred in zip(inputs, test_predictions):\n    show_input(img, title=pred)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:38:38.916702Z","iopub.execute_input":"2024-06-27T08:38:38.917187Z","iopub.status.idle":"2024-06-27T08:38:42.970492Z","shell.execute_reply.started":"2024-06-27T08:38:38.917154Z","shell.execute_reply":"2024-06-27T08:38:42.969566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame.from_dict({'id': test_img_paths, 'label': test_predictions})","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:38:52.591894Z","iopub.execute_input":"2024-06-27T08:38:52.592888Z","iopub.status.idle":"2024-06-27T08:38:52.599747Z","shell.execute_reply.started":"2024-06-27T08:38:52.592851Z","shell.execute_reply":"2024-06-27T08:38:52.598907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df['label'] = submission_df['label'].map(lambda pred: 'dirty' if pred > 0.8 else 'cleaned')\nsubmission_df['id'] = submission_df['id'].str.replace('/kaggle/working/test/unknown/', '')\nsubmission_df['id'] = submission_df['id'].str.replace('.jpg', '')\nsubmission_df.set_index('id', inplace=True)\nsubmission_df.head(n=6)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:39:01.468105Z","iopub.execute_input":"2024-06-27T08:39:01.468509Z","iopub.status.idle":"2024-06-27T08:39:01.493687Z","shell.execute_reply.started":"2024-06-27T08:39:01.468476Z","shell.execute_reply":"2024-06-27T08:39:01.492783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:39:10.652387Z","iopub.execute_input":"2024-06-27T08:39:10.653287Z","iopub.status.idle":"2024-06-27T08:39:10.661837Z","shell.execute_reply.started":"2024-06-27T08:39:10.653249Z","shell.execute_reply":"2024-06-27T08:39:10.660818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf train val test","metadata":{"execution":{"iopub.status.busy":"2024-06-27T08:39:19.444564Z","iopub.execute_input":"2024-06-27T08:39:19.444938Z","iopub.status.idle":"2024-06-27T08:39:20.437058Z","shell.execute_reply.started":"2024-06-27T08:39:19.444908Z","shell.execute_reply":"2024-06-27T08:39:20.435877Z"},"trusted":true},"execution_count":null,"outputs":[]}]}